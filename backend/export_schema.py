#!/usr/bin/env python3
"""
Export database schema from local database to SQL file
This script extracts only the schema (table structures, indexes, constraints)
without the data, ensuring consistent database structure across environments.
"""

import os
import sys
import subprocess
from datetime import datetime
from app import create_app, db
from sqlalchemy import inspect, text

def export_schema_postgresql():
    """Export PostgreSQL schema using pg_dump"""
    print("üìã Exporting PostgreSQL schema...")
    
    # Get database URL from environment
    database_url = os.environ.get('DATABASE_URL', '')
    if not database_url or not database_url.startswith('postgresql'):
        print("‚ùå No PostgreSQL DATABASE_URL found")
        return None
    
    # Parse database URL
    # Format: postgresql://user:password@host:port/dbname
    try:
        from urllib.parse import urlparse
        parsed = urlparse(database_url)
        
        db_params = {
            'host': parsed.hostname or 'localhost',
            'port': parsed.port or 5432,
            'user': parsed.username,
            'password': parsed.password,
            'dbname': parsed.path[1:] if parsed.path else 'troupe_db'
        }
    except Exception as e:
        print(f"‚ùå Error parsing DATABASE_URL: {e}")
        return None
    
    # Create export filename with timestamp
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    export_file = f'migrations/schema_export_{timestamp}.sql'
    
    # Ensure migrations directory exists
    os.makedirs('migrations', exist_ok=True)
    
    # Build pg_dump command for schema only
    env = os.environ.copy()
    env['PGPASSWORD'] = db_params['password']
    
    cmd = [
        'pg_dump',
        '-h', str(db_params['host']),
        '-p', str(db_params['port']),
        '-U', db_params['user'],
        '-d', db_params['dbname'],
        '--schema-only',  # Export only schema, no data
        '--no-owner',     # Don't include ownership statements
        '--no-privileges', # Don't include privilege statements
        '--if-exists',    # Add IF EXISTS to DROP statements
        '-f', export_file
    ]
    
    try:
        result = subprocess.run(cmd, env=env, capture_output=True, text=True)
        if result.returncode == 0:
            print(f"‚úÖ Schema exported to {export_file}")
            return export_file
        else:
            print(f"‚ùå pg_dump failed: {result.stderr}")
            return None
    except FileNotFoundError:
        print("‚ùå pg_dump not found. Please install PostgreSQL client tools.")
        return None
    except Exception as e:
        print(f"‚ùå Error running pg_dump: {e}")
        return None

def export_schema_simple():
    """Simple schema export using create_all SQL capture"""
    print("üìã Exporting schema using simple SQLAlchemy method...")
    
    app = create_app()
    
    # Create export filename with timestamp
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    export_file = f'migrations/schema_export_{timestamp}.sql'
    
    # Ensure migrations directory exists
    os.makedirs('migrations', exist_ok=True)
    
    with app.app_context():
        try:
            # Create a temporary in-memory SQLite database to capture CREATE statements
            from sqlalchemy import create_engine
            from io import StringIO
            
            # Create an engine that will capture SQL
            temp_engine = create_engine("sqlite:///:memory:", echo=False)
            
            # Capture the CREATE statements
            sql_statements = []
            
            def dump(sql, *multiparams, **params):
                sql_statements.append(str(sql.compile(dialect=temp_engine.dialect)) + ';')
            
            temp_engine.execute = dump
            
            # Generate all CREATE TABLE statements
            db.metadata.create_all(temp_engine, checkfirst=False)
            
            # Convert SQLite statements to PostgreSQL-compatible statements
            pg_statements = []
            pg_statements.append("-- Database schema export generated by SQLAlchemy (Simple)")
            pg_statements.append(f"-- Generated at: {datetime.now().isoformat()}")
            pg_statements.append("-- This file contains only the database structure (no data)")
            pg_statements.append("")
            
            for stmt in sql_statements:
                # Convert SQLite to PostgreSQL syntax
                pg_stmt = stmt.replace('DATETIME', 'TIMESTAMP')
                pg_stmt = pg_stmt.replace('TEXT', 'TEXT')
                pg_stmt = pg_stmt.replace('BOOLEAN', 'BOOLEAN')
                pg_stmt = pg_stmt.replace('JSON', 'JSONB')
                
                # Add DROP IF EXISTS for safety
                if pg_stmt.startswith('CREATE TABLE'):
                    table_name = pg_stmt.split()[2]
                    pg_statements.append(f"DROP TABLE IF EXISTS {table_name} CASCADE;")
                
                pg_statements.append(pg_stmt)
                pg_statements.append("")
            
            # Write to file
            with open(export_file, 'w') as f:
                f.write("\n".join(pg_statements))
            
            print(f"‚úÖ Simple schema exported to {export_file}")
            file_size = os.path.getsize(export_file)
            print(f"üìä File size: {file_size:,} bytes")
            
            return export_file
            
        except Exception as e:
            print(f"‚ùå Simple export failed: {e}")
            return None

def export_schema_sqlalchemy():
    """Export schema using SQLAlchemy (fallback method)"""
    print("üìã Exporting schema using SQLAlchemy...")
    
    app = create_app()
    
    # Create export filename with timestamp
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    export_file = f'migrations/schema_export_{timestamp}.sql'
    
    # Ensure migrations directory exists
    os.makedirs('migrations', exist_ok=True)
    
    with app.app_context():
        # Get all table creation SQL
        create_statements = []
        
        # Add header
        create_statements.append("-- Database schema export generated by SQLAlchemy")
        create_statements.append(f"-- Generated at: {datetime.now().isoformat()}")
        create_statements.append("-- This file contains only the database structure (no data)")
        create_statements.append("")
        
        # Get metadata and handle cycles
        metadata = db.metadata
        
        # Get tables in a safe order (handle cycles)
        try:
            tables = list(metadata.sorted_tables)
        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: {e}")
            # Fall back to unsorted tables
            tables = list(metadata.tables.values())
        
        # Generate DROP statements first (in reverse order)
        create_statements.append("-- Drop existing tables")
        for table in reversed(tables):
            create_statements.append(f"DROP TABLE IF EXISTS {table.name} CASCADE;")
        create_statements.append("")
        
        # Generate CREATE TABLE statements
        for table in tables:
            create_statements.append(f"-- Table: {table.name}")
            
            # Build CREATE TABLE statement manually
            create_stmt = f"CREATE TABLE {table.name} ("
            columns = []
            
            for column in table.columns:
                # Get column type as string
                col_type = str(column.type)
                
                # Handle special PostgreSQL types
                if 'VARCHAR' in col_type.upper():
                    if '(None)' in col_type:
                        col_type = 'TEXT'
                elif 'BOOLEAN' in col_type.upper():
                    col_type = 'BOOLEAN'
                elif 'INTEGER' in col_type.upper():
                    col_type = 'INTEGER'
                elif 'DATETIME' in col_type.upper():
                    col_type = 'TIMESTAMP'
                elif 'JSON' in col_type.upper():
                    col_type = 'JSONB'
                
                col_def = f"    {column.name} {col_type}"
                
                # Add constraints
                if column.primary_key:
                    col_def += " PRIMARY KEY"
                if not column.nullable and not column.primary_key:
                    col_def += " NOT NULL"
                if column.default is not None:
                    default_val = column.default
                    if hasattr(default_val, 'arg'):
                        if callable(default_val.arg):
                            # Skip complex defaults like uuid functions
                            pass
                        else:
                            col_def += f" DEFAULT {default_val.arg}"
                    elif hasattr(default_val, 'value'):
                        col_def += f" DEFAULT {default_val.value}"
                
                columns.append(col_def)
            
            create_stmt += "\n" + ",\n".join(columns) + "\n);"
            create_statements.append(create_stmt)
            create_statements.append("")
        
        # Generate foreign key constraints separately (to avoid cycles)
        create_statements.append("-- Foreign Key Constraints")
        for table in tables:
            for fk in table.foreign_keys:
                fk_stmt = f"ALTER TABLE {table.name} ADD CONSTRAINT fk_{table.name}_{fk.column.name} "
                fk_stmt += f"FOREIGN KEY ({fk.parent.name}) REFERENCES {fk.column.table.name} ({fk.column.name});"
                create_statements.append(fk_stmt)
        create_statements.append("")
        
        # Generate indexes
        create_statements.append("-- Indexes")
        for table in tables:
            for index in table.indexes:
                if not index.unique:  # Skip unique indexes (they're usually handled by constraints)
                    index_cols = ", ".join([col.name for col in index.columns])
                    index_stmt = f"CREATE INDEX IF NOT EXISTS {index.name} ON {table.name} ({index_cols});"
                    create_statements.append(index_stmt)
        
        # Write to file
        with open(export_file, 'w') as f:
            f.write("\n".join(create_statements))
        
        print(f"‚úÖ Schema exported to {export_file}")
        
        # Show some stats
        file_size = os.path.getsize(export_file)
        print(f"üìä Exported {len(tables)} tables ({file_size:,} bytes)")
        
        return export_file

def create_latest_schema_link(export_file):
    """Create a symlink to the latest schema export"""
    if export_file and os.path.exists(export_file):
        latest_link = 'migrations/latest_schema.sql'
        
        # Remove existing symlink if it exists
        if os.path.exists(latest_link) or os.path.islink(latest_link):
            os.remove(latest_link)
        
        # Create new symlink (relative path)
        os.symlink(os.path.basename(export_file), latest_link)
        print(f"‚úÖ Created symlink: {latest_link} -> {export_file}")

def main():
    """Main function to export database schema"""
    print("üöÄ Starting database schema export...\n")
    
    export_file = None
    
    # Try PostgreSQL export first (preferred)
    export_file = export_schema_postgresql()
    
    # Fallback to complex SQLAlchemy if PostgreSQL export fails
    if not export_file:
        print("\n‚ö†Ô∏è  Falling back to SQLAlchemy export method...")
        export_file = export_schema_sqlalchemy()
    
    # Final fallback to simple SQLAlchemy method
    if not export_file:
        print("\n‚ö†Ô∏è  Falling back to simple SQLAlchemy method...")
        export_file = export_schema_simple()
    
    if export_file:
        # Create symlink to latest export
        create_latest_schema_link(export_file)
        
        print(f"\n‚úÖ Schema export completed successfully!")
        print(f"üìÅ Export file: {export_file}")
        print(f"üìé Latest schema: migrations/latest_schema.sql")
        
        # Show file size and contents preview
        file_size = os.path.getsize(export_file)
        print(f"üìä File size: {file_size:,} bytes")
        
        # Show first few lines as preview
        try:
            with open(export_file, 'r') as f:
                lines = f.readlines()[:10]
                print(f"\nüìù Preview (first 10 lines):")
                for i, line in enumerate(lines, 1):
                    print(f"  {i:2d}: {line.rstrip()}")
                if len(lines) == 10:
                    print("  ...")
        except Exception:
            pass
        
        return 0
    else:
        print("\n‚ùå All schema export methods failed!")
        print("üí° Please check your database connection and models.py file")
        return 1

if __name__ == "__main__":
    sys.exit(main())